{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{ORANGE}{\\text{U-NET IN STEEL   }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Цели и задачи\n",
    "**Описание ноутбука**\n",
    "- В ноутбуке запустила небольшую сеть Unet и предобученную Small-YOLO. \n",
    "- Результаты фиксировала в https://wandb.ai/eliseeva/severstal\n",
    "\n",
    "**Выводы**\n",
    "- Базовая Unet дала лучший результат. \n",
    "\n",
    "**Что еще можно сделать**\n",
    "- Можно попробовать улучшить, увеличив количество эпох.\n",
    "- В дальнейшем можно добавить callbacks (ReduceLROnPlateau), определить lr (1e-3), добавить метрики (Dice Loss, IoU Loss, pixel_accuracy), поменять loss.\n",
    "- Попробовать https://www.tensorflow.org/tutorials/keras/keras_tuner.\n",
    "- Перенести DeeplabV3Plus и tiramisu, Unet('resnet34')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные и необходимые модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-27T12:30:15.055066Z",
     "iopub.status.busy": "2021-12-27T12:30:15.054727Z"
    }
   },
   "outputs": [],
   "source": [
    "#добавляем библиотеки\n",
    "import os\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Conv2D, BatchNormalization, Dropout\n",
    "from keras.models import Model, load_model \n",
    "import gc\n",
    "!pip install segmentation-models\n",
    "!pip install git+https://github.com/qubvel/segmentation_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T12:57:27.620578Z",
     "iopub.status.busy": "2021-12-24T12:57:27.620194Z",
     "iopub.status.idle": "2021-12-24T12:57:28.558626Z",
     "shell.execute_reply": "2021-12-24T12:57:28.557931Z",
     "shell.execute_reply.started": "2021-12-24T12:57:27.620544Z"
    }
   },
   "outputs": [],
   "source": [
    "# загружаем данные\n",
    "trainImgPath = \"/kaggle/input/severstal-steel-defect-detection/train_images/\"\n",
    "trainCsv = \"/kaggle/input/severstal-steel-defect-detection/train.csv\"\n",
    "data=pd.read_csv(trainCsv)\n",
    "data.ClassId=data.ClassId.astype(int)\n",
    "\n",
    "train_Img_Id = []\n",
    "train_class_Id = []\n",
    "for i in os.listdir(trainImgPath):\n",
    "    for j in range(1,5):\n",
    "        train_Img_Id.append(i)\n",
    "        train_class_Id.append(j)\n",
    "train_Imgs = pd.DataFrame({'ImageId':train_Img_Id,'ClassId':train_class_Id})\n",
    "train_Imgs.head(10)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка к обучению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как одно изображение может использоваться для разных дефектов, то мы подготовим новую таблицу, в которой сделаем объединение по изображению и укажем координаты пискселей с дефектами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T12:57:31.699518Z",
     "iopub.status.busy": "2021-12-24T12:57:31.699192Z",
     "iopub.status.idle": "2021-12-24T12:57:31.746472Z",
     "shell.execute_reply": "2021-12-24T12:57:31.745769Z",
     "shell.execute_reply.started": "2021-12-24T12:57:31.699488Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.merge(train_Imgs,data ,how='outer', on=['ImageId','ClassId']) \n",
    "train_data = train_data.fillna('') \n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T12:57:37.306417Z",
     "iopub.status.busy": "2021-12-24T12:57:37.306068Z",
     "iopub.status.idle": "2021-12-24T12:57:44.766817Z",
     "shell.execute_reply": "2021-12-24T12:57:44.765947Z",
     "shell.execute_reply.started": "2021-12-24T12:57:37.306385Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.pivot_table(train_data, values='EncodedPixels', index='ImageId',columns='ClassId', aggfunc=np.sum).astype(str)\n",
    "train_data = train_data.reset_index() # add Index column to one level with classID   \n",
    "train_data.columns = ['ImageId','Defect_1','Defect_2','Defect_3','Defect_4'] \n",
    "has_defect = []\n",
    "stratify = []\n",
    "for index,row in train_data.iterrows():\n",
    "    if row.Defect_1 or row.Defect_2 or row.Defect_3 or row.Defect_4: \n",
    "        has_defect.append(1)\n",
    "    else:\n",
    "        has_defect.append(0) \n",
    "    if row.Defect_1 != '':\n",
    "        stratify.append(1)\n",
    "    elif row.Defect_2 != '':\n",
    "        stratify.append(2)\n",
    "    elif row.Defect_3:\n",
    "        stratify.append(3)\n",
    "    elif row.Defect_4:\n",
    "        stratify.append(4)\n",
    "    else:\n",
    "        stratify.append(0)\n",
    "        \n",
    "train_data[\"has_defect\"] = has_defect \n",
    "train_data[\"stratify\"] = stratify \n",
    "\n",
    "train_data.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T12:57:44.769140Z",
     "iopub.status.busy": "2021-12-24T12:57:44.768762Z",
     "iopub.status.idle": "2021-12-24T12:57:44.799569Z",
     "shell.execute_reply": "2021-12-24T12:57:44.798728Z",
     "shell.execute_reply.started": "2021-12-24T12:57:44.769102Z"
    }
   },
   "outputs": [],
   "source": [
    "# вынести рандом стейт или сделать shuffle=True\n",
    "WIDTH=288\n",
    "HEIGHT=288\n",
    "TRAINING_SIZE=7095\n",
    "\n",
    "x_train, x_test = train_test_split(train_data, test_size = 0.1, stratify=train_data['stratify'], random_state=42)\n",
    "x_train, x_val = train_test_split(x_train, test_size = 0.2, stratify = x_train['stratify'], random_state=42)\n",
    "print(x_train.shape, x_val.shape, x_test.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T12:57:44.801436Z",
     "iopub.status.busy": "2021-12-24T12:57:44.801082Z",
     "iopub.status.idle": "2021-12-24T12:57:44.817091Z",
     "shell.execute_reply": "2021-12-24T12:57:44.816169Z",
     "shell.execute_reply.started": "2021-12-24T12:57:44.801400Z"
    }
   },
   "outputs": [],
   "source": [
    "# разделим выборку на тестовую, обучающую и валидационную\n",
    "x_train_classification = x_train[['ImageId','has_defect']]\n",
    "x_val_classification = x_val[['ImageId','has_defect']]\n",
    "x_test_classification = x_test[['ImageId','has_defect']] \n",
    "print(x_train_classification.shape , x_val_classification.shape,x_test_classification.shape)\n",
    "x_train_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-24T12:57:44.819466Z",
     "iopub.status.busy": "2021-12-24T12:57:44.818657Z",
     "iopub.status.idle": "2021-12-24T12:58:04.185045Z",
     "shell.execute_reply": "2021-12-24T12:58:04.182875Z",
     "shell.execute_reply.started": "2021-12-24T12:57:44.819427Z"
    }
   },
   "outputs": [],
   "source": [
    "# подготовим генератор для аугментации данных\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "train_datagen = ImageDataGenerator(rescale=1./255., shear_range=0.2, zoom_range=0.05, rotation_range=5,\n",
    "                           width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=x_train_classification.astype(str),\n",
    "        directory=trainImgPath,\n",
    "        x_col=\"ImageId\",\n",
    "        y_col=\"has_defect\",\n",
    "        target_size=(WIDTH,HEIGHT),\n",
    "        batch_size=16,\n",
    "        class_mode='binary') \n",
    "\n",
    "valid_data_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=x_val_classification.astype(str),\n",
    "        directory=trainImgPath,\n",
    "        x_col=\"ImageId\",\n",
    "        y_col=\"has_defect\",\n",
    "        target_size=(WIDTH,HEIGHT),\n",
    "        batch_size=16,\n",
    "        class_mode='binary') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-22T10:54:56.923589Z",
     "iopub.status.busy": "2021-12-22T10:54:56.923255Z",
     "iopub.status.idle": "2021-12-22T10:54:57.329032Z",
     "shell.execute_reply": "2021-12-22T10:54:57.328149Z",
     "shell.execute_reply.started": "2021-12-22T10:54:56.923555Z"
    }
   },
   "outputs": [],
   "source": [
    "# импортируем wandb для наблюдения за обучением\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"severstal\", entity=\"eliseeva\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T09:18:06.775035Z",
     "iopub.status.busy": "2021-12-21T09:18:06.774664Z",
     "iopub.status.idle": "2021-12-21T09:18:06.782364Z",
     "shell.execute_reply": "2021-12-21T09:18:06.781397Z",
     "shell.execute_reply.started": "2021-12-21T09:18:06.775003Z"
    }
   },
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "#   \"learning_rate\": 0.001,\n",
    "  \"epochs\": 30,\n",
    "  \"batch_size\": 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T09:08:20.346477Z",
     "iopub.status.busy": "2021-12-21T09:08:20.346128Z",
     "iopub.status.idle": "2021-12-21T09:08:24.754353Z",
     "shell.execute_reply": "2021-12-21T09:08:24.751956Z",
     "shell.execute_reply.started": "2021-12-21T09:08:20.346445Z"
    }
   },
   "outputs": [],
   "source": [
    "# загружаем модель\n",
    "Classification_Model = keras.applications.xception.Xception(include_top = False, input_shape = (HEIGHT,WIDTH,3))\n",
    "\n",
    "layer = Classification_Model.output\n",
    "layer = GlobalAveragePooling2D()(layer)\n",
    "\n",
    "layer = Dense(1024, activation='relu')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "\n",
    "layer = Dense(512, activation='relu')(layer)\n",
    "layer = BatchNormalization()(layer)\n",
    "layer = Dropout(0.3)(layer)\n",
    "\n",
    "layer = Dense(64, activation='relu')(layer)\n",
    "predictions = Dense(1, activation='sigmoid')(layer)\n",
    "model = Model(inputs=Classification_Model.input, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T09:18:17.728613Z",
     "iopub.status.busy": "2021-12-21T09:18:17.728252Z",
     "iopub.status.idle": "2021-12-21T11:59:25.814443Z",
     "shell.execute_reply": "2021-12-21T11:59:25.813714Z",
     "shell.execute_reply.started": "2021-12-21T09:18:17.728583Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "Training = model.fit(train_data_generator, validation_data = valid_data_generator, callbacks=[WandbCallback()], epochs = 30, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты обучения можно посмотреть здесь - https://wandb.ai/eliseeva/severstal, кривая base-Xeption. Максимальный результат по accuracy - 0.9334. По графику кажется, что можно увеличить количество эпох для лучшего результата. \n",
    "\n",
    "В дальнейшем можно добавить callbacks (ReduceLROnPlateau), определить lr (1e-3), добавить метрики (Dice Loss, IoU Loss, pixel_accuracy), поменять loss.\n",
    "Попробовать https://www.tensorflow.org/tutorials/keras/keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small-YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T12:44:24.579017Z",
     "iopub.status.busy": "2021-12-21T12:44:24.578682Z",
     "iopub.status.idle": "2021-12-21T12:44:28.631345Z",
     "shell.execute_reply": "2021-12-21T12:44:28.63053Z",
     "shell.execute_reply.started": "2021-12-21T12:44:24.578987Z"
    }
   },
   "outputs": [],
   "source": [
    "# загружаем модель\n",
    "base_model = keras.applications.Xception(input_shape=(288,288,3),include_top=False,weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T12:44:30.886335Z",
     "iopub.status.busy": "2021-12-21T12:44:30.885899Z",
     "iopub.status.idle": "2021-12-21T12:44:30.895882Z",
     "shell.execute_reply": "2021-12-21T12:44:30.894561Z",
     "shell.execute_reply.started": "2021-12-21T12:44:30.886262Z"
    }
   },
   "outputs": [],
   "source": [
    "# замораживаем слои\n",
    "for layer in base_model.layers[:-5]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T13:04:10.110781Z",
     "iopub.status.busy": "2021-12-21T13:04:10.110436Z",
     "iopub.status.idle": "2021-12-21T13:04:10.459504Z",
     "shell.execute_reply": "2021-12-21T13:04:10.45871Z",
     "shell.execute_reply.started": "2021-12-21T13:04:10.110751Z"
    }
   },
   "outputs": [],
   "source": [
    "# строим модель\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dense(4,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предобученная Small-YOLO не дала прироста качества (кривая Small-YOLO). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
